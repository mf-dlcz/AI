# Prompting

1. User input prompt
2. Tokenizer (Create Tokens)
3. Embedding (Create embedding)
4. LLMs (Completion)
5. Ouput Format Conversion
6. Generated Output to User


- When you provide an input prompt, the system first breaks it down into smaller units, 
called tokens, through a process called tokenization.

- Next, the embedding step converts the tokens into numerical representations, called 
embeddings. 

- The LLM then takes the embeddings as input. The LLM generates an encoded output, which 
is known as the completion step. 

- The completion step might involve a single round for text-based conversations or multiple 
rounds for chat-based conversations. 

- Finally, the system converts the encoded output into the desired format, such as text, 
and presents it as the final output.


## System, user, and assistant messages

### <ins>System Messages<ins>
- System messages provide general instructions, assumptions, or rules for AI to follow 
during a conversation.

- System messages include directing AI to assume a particular persona or providing 
context about an upcoming conversation.


### <ins>User Messages<ins>
- User messages contain the actual input or query from a human user.

- This could be a question, statement, piece of data, or any combination thereof.


### <ins>Assistant Messages<ins>
- Assistant messages are the responses generated by an AI model in reaction to user messages. 

- These responses take into account a user's input, as well as any instructions or context 
provided in the system messages. 

- Assistant messages aim to provide relevant, coherent, and helpful information to address a 
user's query or prompt.


> [!NOTE]  
> During a conversation, users initiate an interaction by providing their input through user 
> messages. The assistant interprets the messages and generates relevant, coherent responses 
> in the form of assistant messages. Throughout this process, system messages play a crucial 
> role in guiding a model's behavior, persona, and output. System messages ensure that the 
> assistant adheres to the objectives and constraints set by developers or administrators, 
> enabling a tailored and controlled conversational experience.